{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e0ffed-8b9e-44b0-b411-4714402c68aa",
   "metadata": {},
   "source": [
    "# Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1155d9d-8daa-4200-8149-96b433fd5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe3811-879f-4126-b397-877ac2179ffa",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0f67ee-841d-445c-97bd-b0c7fbedbc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/ktxdev/transfomers-hf/refs/heads/master/data/imdb_small.csv\"\n",
    "dataset = load_dataset(\"csv\", data_files=dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0879a-f08b-490b-878b-cc85456a609e",
   "metadata": {},
   "source": [
    "# Inspect Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc8411-8a1d-463e-aca8-a93a09d30d60",
   "metadata": {},
   "source": [
    "## Dataset dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b1163d-392c-431d-b4ca-a0257bf58188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review', 'sentiment'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963be40b-f9b8-4d57-871a-7992dd237b57",
   "metadata": {},
   "source": [
    "## Single record inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b51249-db8b-4a3b-a168-a18a1c417c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 76,\n",
       " 'review': \"The Last Hard Men finds James Coburn an outlaw doing a long sentence breaking free from a chain gang. Do he and his friends head for the Mexican border from jail and safety. No they don't because Coburn has a mission of revenge. To kill the peace officer who brought him in and in the process killed his woman.<br /><br />That peace officer is Charlton Heston who is now retired and he knows what Coburn is after. As he explains it to his daughter, Barbara Hershey, Coburn was holed up in a shack and was involved in a Waco like standoff. His Indian woman was killed in the hail of bullets fired. It's not something he's proud of, she was a collateral casualty in a manhunt.<br /><br />Lest we feel sorry for Coburn he lets us know full well what an evil man he truly is. Heston is his usual stalwart hero, but the acting honors in The Last Hard Men go to James Coburn. He blows everyone else off the screen when he's on. <br /><br />Coburn gets the bright idea of making sure Heston trails him by kidnapping Hershey and taking her to an Indian reservation where the white authorities can't touch him. He knows that Heston has to make it personal then.<br /><br />Coburn's gang includes, Morgan Paull, Thalmus Rasulala, John Quade, Larry Wilcox, and Jorge Rivero. Heston has Chris Mitchum along who is his son-in-law to be.<br /><br />The Last Hard Men is one nasty and brutal western. Andrew McLaglen directed it and I'm thinking it may have been a project originally intended for Sam Peckinpaugh. It sure shows a lot of his influence with the liberal use of slow motion to accentuate the violence. Of which there is a lot. <br /><br />For a little Peckinpaugh lite, The Last Hard Men is your film.\",\n",
       " 'sentiment': 'positive'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e5b67-7312-48dc-9713-5447c900166d",
   "metadata": {},
   "source": [
    "# Remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcf19b2-117f-41e7-83dd-7bc155417203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns(['Unnamed: 0'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01edebc-a8d0-4b94-bdc4-dad53e340e1d",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ee9cc8-f45e-499e-9bc6-ddea3ee22b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.\\n\\nThe first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.\\n\\nIt is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.\\n\\nI would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\",\n",
       " 'sentiment': 'positive'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(example):\n",
    "    \"\"\"Removes HTML tags\"\"\"\n",
    "    text = html.unescape(example['review'])\n",
    "    text = re.sub(r\"<br\\s*/?>\", \"\\n\", text)\n",
    "    text = text.strip()\n",
    "    example['review'] = text\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(preprocess_text)\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2375c0-358d-4816-882c-c075ce9553c9",
   "metadata": {},
   "source": [
    "# Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b77439-4bb6-4ad1-a38a-313e50529b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "label2id = {'negative': 0, 'positive': 1}\n",
    "\n",
    "def tokenize_dataset(examples):\n",
    "    inputs = tokenizer(examples['review'], truncation=True)\n",
    "    inputs['labels'] = [label2id[sentiment] for sentiment in examples['sentiment']]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d8736-525d-4084-984f-f531f19265a5",
   "metadata": {},
   "source": [
    "# Split dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4d3ba4-5ccf-462a-804a-fa822a37dc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and test\n",
    "train_test = tokenized_dataset['train'].train_test_split(test_size=0.3)\n",
    "# Split test into validation and test\n",
    "val_test = train_test['test'].train_test_split(test_size=0.5)\n",
    "# Create final dataset\n",
    "final_dataset = DatasetDict({\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"validation\": val_test[\"train\"],\n",
    "    \"test\": val_test[\"test\"],\n",
    "})\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01391aa4-8ebb-47f1-b91e-880d85be4c01",
   "metadata": {},
   "source": [
    "# Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e52c46-7379-44ba-b679-ccec21310849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy, precision, recall and f1 score for evaluation\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = np.round(accuracy_score(labels, predictions), 3)\n",
    "    precision = np.round(precision_score(labels, predictions, average=\"weighted\"), 3)\n",
    "    recall = np.round(recall_score(labels, predictions, average=\"weighted\"), 3)\n",
    "    f1 = np.round(f1_score(labels, predictions, average=\"weighted\"), 3)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52a5cb-9548-4bc0-b3a7-a7eee8c5023a",
   "metadata": {},
   "source": [
    "# Load Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d389408-5771-4cb1-be9a-f2981f95858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Load model with binary classification head\n",
    "id2label = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    num_labels=2, \n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "# Move to hardware accelerator if available\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cdaae-0a00-43c4-90ec-666c632bb0e5",
   "metadata": {},
   "source": [
    "# Create the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a195cec-3183-4671-8157-cf870f467c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-4\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"bert-imdb-sentiment-analyzer\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28411e-443f-4ab5-93e5-005a05498cb9",
   "metadata": {},
   "source": [
    "# Freeze some parameters to reduce computational costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c88918-04a7-4d79-b890-c8b6df3fdd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freaze all base model parameters\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# unfreeze the last 2 transformer layers\n",
    "for param in model.base_model.encoder.layer[-2:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# unfreeze the classification head\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f16007-e507-4ff3-94bd-6099d9a34946",
   "metadata": {},
   "source": [
    "# Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9588a4bb-aaa9-4b1c-9ca4-6cfac617d78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 02:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>0.232654</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.199887</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.198141</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.261396</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.939000</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.293878</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.939000</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.934000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=110, training_loss=0.23642236427827315, metrics={'train_runtime': 178.1988, 'train_samples_per_second': 19.641, 'train_steps_per_second': 0.617, 'total_flos': 920724249350400.0, 'train_loss': 0.23642236427827315, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=final_dataset['train'],\n",
    "    eval_dataset=final_dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba8490-475c-4bd3-af86-89dafda5696b",
   "metadata": {},
   "source": [
    "# Validate with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5033a6e-2c3e-49b4-a16b-64f2e646c655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': np.float64(0.893), 'precision': np.float64(0.897), 'recall': np.float64(0.893), 'f1': np.float64(0.893)}\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(final_dataset['test'])\n",
    "\n",
    "logits, labels = predictions.predictions, predictions.label_ids\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796832f7-e4ac-4c18-9ecf-78d26287e687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
